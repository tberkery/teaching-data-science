---
title: "Joins and Visualizations in R"
author: "Tad Berkery" # here, replace my name with your name
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Tutorial developed by Tad Berkery.

## Load Libraries
```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
library(reactable)
library(ggplot2) # We will talk about this library (not previously introduced) today.
```

If any of these libraries aren't yet installed (i.e. you get an error when executing the above code cell), copy and paste the following into the Console and hit enter.
```{}
install.packages("tidyverse")
install.packages("reactable")
install.packages("ggplot2")
```

# Joins

## Introduction

By this point, you have completed the data conditioning tutorial and have a familiarity with libraries, functions, dataframes, the piping operator, and many foundational `tidyverse` functions, including `SELECT`, `MUTATE`, `GROUP BY`, `FILTER`, and `SUMMARIZE`. Now, we will build on your understanding of these functions and discuss another key series of functions: joins.

Joins provide a framework for uniting records across multiple tables by specifying a methodology for relating records. The idea is to "join" multiple tables together into a single table with more information. It is important to highlight that the concept of joins is not at all unique to R (in fact, most of the earlier tidyverse functions conceptually aren't limited to just R either). For example, Structured Query Language (abbreviated SQL and pronounced "sequel"), which is a language for pulling data from databases, has select, distinct, group by, filter, and join statements (among many others) that work in a similar manner. However, we will focus on introducing joins for the purpose of building your knowledge of how to analyze data in R with a mindset that understanding how these concepts work in one language is a great way to be able to easily learn to use them in other languages as well.

## Acquire Data
Recall that in the last tutorial we reviewed how to acquire data easily from [*Baseball Reference*](https://www.baseball-reference.com/) on its website. Download the [2023 "Player Standard Batting" table](https://www.baseball-reference.com/leagues/majors/2023-standard-batting.shtml) (remember that this is the *second* table on this webpage), the [2022 "Player Standard Batting" table](https://www.baseball-reference.com/leagues/majors/2022-standard-batting.shtml), and the [2021 "Player Standard Batting" table](https://www.baseball-reference.com/leagues/majors/2021-standard-batting.shtml). Make sure that the CSVs for each end up in this directory named in the format "br_batting_leaderboard_[year].csv".

```{r, message = FALSE, warning = FALSE}
bl_23 = read_csv("br_batting_leaderboard_2023.csv")
bl_22 = read_csv("br_batting_leaderboard_2022.csv")
bl_21 = read_csv("br_batting_leaderboard_2021.csv")
```

Recall from the last tutorial that I define and call several functions to clean up this data. Don't worry about how these work, just note that I call them again here.

```{r, message = FALSE, warning = FALSE}
remove_lg_avg_summary = function(df) {
  df = df[-nrow(df), ]
  df = filter(df, Tm != 'TOT')
  return(df)
}
remove_special_characters = function(df, special_characters) {
  df[] <- lapply(df, function(x) gsub(special_characters, "", x))
  return(df)
}

identify_numeric_columns = function(df) {
  is_numeric_column <- function(x) {
    all(grepl("^\\d+\\.?\\d*$", x))
  }
  for (col_name in names(df)) {
    if (is_numeric_column(df[[col_name]])) {
      df[[col_name]] <- as.numeric(df[[col_name]])
    }
  }
  df = mutate(df, BA = as.numeric(BA), OBP = as.numeric(OBP),
              SLG = as.numeric(SLG), OPS = as.numeric(OPS),
              `OPS+` = as.numeric(`OPS+`))
  return(df)
}

bl_23 = bl_23 %>%
  remove_lg_avg_summary() %>%
  remove_special_characters("[*#]") %>%
  identify_numeric_columns()

bl_22 = bl_22 %>%
  remove_lg_avg_summary() %>%
  remove_special_characters("[*#]") %>%
  identify_numeric_columns()

bl_21 = bl_21 %>%
  remove_lg_avg_summary() %>%
  remove_special_characters("[*#]") %>%
  identify_numeric_columns()

```

### Challenge
(Optional) If you are extra curious about R and want to learn more (beyond just this tutorial), google what a for loop is and checkout the `paste0` function online. Then see if you can write a for loop that delivers the same functionality of the previous cell. Would it save you lines of code if, say, I asked you to read a CSV for every season between 2000 and today?

```{r, message = FALSE, warning = FALSE}
# YOUR SOLUTION HERE
```

## Motivating Joins
Imagine that you are considering signing some batters and want to take a cursory look at their stats. You could solely consider their stats in the most recent year, but having several years might paint a more complete picture. How can you consider multiple seasons within a single dataframe (instead of having to manually search for, e.g. Christian Walker, in 3 separate dataframes)?

One way to do this is to **join** dataframes together.

First, let's just work with the data for the 2022 and 2023 seasons. Think about merging these two dataframes together. What information do we need?

1. First, it may seem somewhat self-evident, but a join takes place between two dataframes. That means we need to identify what datarames are at play (and soon consider what commonalities they share).

2. Second, in relation to this question of commonalities, we need some rule of thumb on what determines if two rows are related. For our example, a very sensible pick is to say that when rows refer to the same player name, they should be related (we will discuss soon how this is far from foolproof, but it is a sensible starting point for demonstration).

3. Third, we need to specify what columns in *each* dataframe are relevant for searching for the relation we just identified. For example, image our player name again is Christian Walker. It is highly inefficient to search across every cell in each dataframe for "Christian Walker". However, it is sufficiently efficient to search across the "Name" column in each dataframe. We need to specify this when writing joins.

These three decision points are in many ways the key ingredients of a join.

* Specify the two dataframes at play. Keep in mind that you can use the piping operator when doing this (more on this below).

* Specify what columns (*at least* one from *each* dataframe) establish the relationship. This is often called by **by** clause or the **on** clause of the join (R uses "by", SQL uses "on"... both refer to the same concept).

At this point, we have motivated the concept of a join. Let's now experiment.

Here I have made two small tables that are subsets of the 2022 and 2023 batting dataframes, respectively. Don't worry too much about how I did this if it doesn't make sense... however, hopefully you understand a good portion of it (the usage of `select` and `filter` is within the scope of last week's tutorial, with the one new modification being that I now use the `%in%` operator which checks to the see if the value of the `Name` column for each row is in a vector [basically a list] of names I specify). Regardless of whether that makes sense, take a look at the contents of each table.

```{r, message = FALSE, warning = FALSE}
bl_23_sub = bl_23 %>%
  select(Name, Age, Tm, BA, OBP, SLG, OPS, `OPS+`) %>%
  filter(Name %in% c("Freddie Freeman", "Ketel Marte", "Paul Goldschmidt", "Corey Seager", "Cody Bellinger", "Matt Chapman", "Shohei Ohtani", "Corbin Carroll"))
bl_22_sub = bl_22 %>%
  select(Name, Age, Tm, BA, OBP, SLG, OPS, `OPS+`) %>%
  filter(Name %in% c("Ronald Acuna Jr.", "Ketel Marte", "Nolan Arenado", "Corey Seager", "Xander Bogaerts", "Matt Chapman", "Shohei Ohtani", "Jorge Soler"))
bl_21_sub = bl_21 %>%
  select(Name, Age, Tm, BA, OBP, SLG, OPS, `OPS+`) %>%
  filter(Name %in% c("Ronald Acuna Jr.", "Ketel Marte", "Nolan Arenado", "Corey Seager", "Cody Bellinger", "Matt Chapman", "Aaron Judge", "Yadier Molina"))
```

Checkout the **2023** subset:
```{r, message = FALSE, warning = FALSE}
reactable(bl_23_sub, sortable = TRUE)
```

Checkout the **2022** subset:
```{r, message = FALSE, warning = FALSE}
reactable(bl_22_sub, sortable = TRUE)
```

Checkout the **2021** subset:
```{r, message = FALSE, warning = FALSE}
reactable(bl_21_sub, sortable = TRUE)
```
Note that the list of players I picked in each subset varies by season.

On the defined subsets, let's join the batting data from the 2022 season and 2023 season by player name. (Note the format of this... two dataframes and a criterion involving their columns is very explicitly identified! Try to do this when talking about joins as your first learn them.)

```{r, warning = FALSE, message = FALSE}
joined_22_23 = inner_join(bl_23_sub, bl_22_sub, by = c('Name' = 'Name'))
reactable(joined_22_23, sortable = TRUE)
```

Note that we call the `inner_join` function (this comes from the `tidyverse`... think back to libraries from last tutorial) and specify the `Name` column as the criteria to join on.

* Note that the first dataframe provided is `bl_23_sub` and that the second dataframe provided is `bl_22_sub`. Think directionally for a second: this means that `bl_23_sub` is the *left* dataframe and `bl_22_sub` is the right dataframe. For this exact command, that distinction doesn't matter. However, in subsequent commands and more complicated joins, it will matter a lot.

* Note here that we are choosing to perform an `inner_join`. **An inner join only keeps contents from the left dataframe that also have matches (as defined by your criteria in the `by` clause) in the right dataframe.** This is very important to understand well in time (although it's okay if it doesn't make sense right this second). In contrast to an inner join, a `left_join` (this, too, is a function in R) is a form of outer join where every column in the left dataframe is included regardless of whether it has a match in the right dataframe.

* Note that we end up with `.x` and `.y` suffixes in our column names. A dataframe isn't permitted to have two columns with the same name, so this is how the computer compensates. However, it is very inconvenient (and in the end often borderline impossible) to have to remember that `.x` corresponds to the 2023 season value (since 2023 is the left dataframe) and `.y` corresponds to the 2022 season value (since 2022 is the right dataframe). We can fix this by adding a specification of suffixes as an argument to the inner join function, as shown in this revised command (below). Note that we use `c([element], [element])` notation (the `c()` format indicates a *vector*) and that we put the label we want appended to the name of every column from the left dataframe as the first element and that of the right dataframe as the second.

```{r, message = FALSE, warning = FALSE}
joined_22_23_sub = inner_join(bl_23_sub, bl_22_sub, by = c('Name' = 'Name'), suffix = c('_23', '_22'))
reactable(joined_22_23_sub, sortable = TRUE)
```

### Exercise: Order of Dataframes in Joins
I decide to rename the `Name` column in `bl_23_sub` to `Player_Name`. Rewrite the above inner join to account for this twist. To ensure the following code still works even if your answer to this question is wrong, please replace `NULL` with your inner join call (i.e. save the result of your code to this question in a new variable *not* named `joined_22_23`).
```{r}
bl_23_sub_renamed = bl_23_sub %>%
  rename(Player_Name = Name)
joined_22_23_sub_fresh = NULL # REPLACE NULL WITH YOUR SOLUTION
# A few rules:
# - You cannot simply use the rename function again to trivially solve this problem.
# - You must write an inner join and use bl_23_sub_renamed inside of it. You may not use bl_23_sub in your join.
```

### Exercise: Find My Error
What is wrong with the following? The code runs fine, but there is an error that makes its output misleading. Describe the error in words and then fix the error in code.
```{r, warning = FALSE, message = FALSE}
theres_an_error = bl_23_sub %>%
  inner_join(bl_22_sub, by = c('Name' = 'Name'), suffix = c('_22', '_23'))
reactable(theres_an_error, sortable = TRUE)
```
Hint: if you can't find the error syntactically, pick a player who appears in both dataframes and lookup his stats. This should help to illuminate the issue.

### Exercise: Putting It All Together
Now do an inner join of the `bl_23` dataframe and the `bl_22` dataframe (the entirety of it, not just a subset).
```{r}
joined_22_23 = NULL # REPLACE NULL WITH YOUR SOLUTION
```
Now join `joined_22_23` to `bl_21`. Hint: if you get an error saying one of the columns you specified in the `by` clause isn't in the respective dataframe it needs to be in based on its location in the `by` clause, try using `colnames` to make sure you got the column name correct.
```{r}
colnames(bl_21)
# colnames(joined_22_23)
# uncomment the previous line (remove the "#") once you have solved the previous example
# Code here and above in this cell relates to the hint.

# YOUR SOLUTION HERE
```

### Exercise: Left Joins
You perform a left join as follows:
```{r, warning = FALSE, message = FALSE}
left_joined_latest_seasons = left_join(bl_23_sub, bl_22_sub, by = c('Name' = 'Name'), suffix = c('_23', '_22'))
reactable(left_joined_latest_seasons, sortable = TRUE)
```

How is the `left_joined_latest_seasons` dataframe different than `joined_22_23`? Just comment (no code needed)
```{}
YOUR SOLUTION HERE
```

This time, run the following command. How is the `left_joined_latest_seasons` dataframe different from the `left_joined_latest_seasons_updated` dataframe? Why did this happen?
```{r, warning = FALSE, message = FALSE}
left_joined_latest_seasons_updated = left_join(bl_22_sub, bl_23_sub, by = c('Name' = 'Name'), suffix = c('_22', '_23'))
reactable(left_joined_latest_seasons_updated, sortable = TRUE)
```
```{}
YOUR SOLUTION HERE
```

### Challenge: Sebastian Aho and Hockey
(Optional) In hockey, if you ran a join by simply player name, "Sebastian Aho" would likely cause problems and unexpected behavior in your join. Why? (Hint: this is very much a find-a-needle-in-a-haystack type of question... don't worry or spend too much time on it... it's just a little piece of sports analyst trivia). Why do you think leagues tend to assign players numerical unique IDs?
```{}
# YOUR ANSWER HERE
```
Another hint: what "team" does "Sebastian Aho" play for?

## A Word of Warning

It is very important to specify the `by` clause in a join correctly. If you don't and it doesn't yield a syntax error, it often will result in basically trying to match every row in the left dataframe to every row in the right dataframe. For big datasets, this is very computationally expensive, takes forever, and won't yield a functional result for what you were aiming to build. If your joins in this tutorial aren't running quickly, this is likely what is happening, and you'll need to make revisions.

### Exercise: Retirement, Debuts, and More

Suppose I'm stuck in an alternate universe where all I have is R and *Baseball Reference* data. How can I use joins to identify players who retired or are yet to play in the major leagues since the 2021 season? To be clear, these two outcomes are very different, but, for the sake of this exercise, I'm asking you to consider both (to make it possible to solve without added information).
```{r}
# YOUR SOLUTION HERE
```

Yadier Molina is a famous longtime catcher for the St. Louis Cardinals who retired somewhat recently. Using inner joins, identify in what year he retired (another way to frame this... what is one year greater than the last season he played?).
```{r}
# YOUR SOLUTION HERE
```

When did Corbin Caroll debut in the major leagues? Gunnar Henderson? Julio Rodriguez?
```{r}
# YOUR SOLUTION HERE
```

### Exercise: Projecting Future Batting Average

Imagine that you wish to project batting average for players with at least `100` plate appearances in *each* of the previous 3 seasons.

First, use `filter` (likely three times) to enforce this constraint.
```{r}
# YOUR SOLUTION HERE
```

Next, write an inner join that lets you cleanly track batting averages for every player with at least `100` plate appearances in each year in a single dataframe.
```{r}
# YOUR SOLUTION HERE
```

In words (no code needed for this part), explain why Orioles star Gunnar Henderson and Nationals first baseman Ryan Zimmerman are not in the single dataframe.
```{}
YOUR SOLUTION HERE
```

Imagine a(n) (over)simplistic algorithm for projecting batting average. Let the projection for batting average in `Year n + 1` be the average of observed batting average in `Year n`, `Year n - 1`, and `Year n - 2`. That is, projection of 2024 batting average for any given player is the average of their batting average in 2021, 2022, and 2023. Use `mutate` and your understanding of how averages are calculated to implement this. 

One remark: if your intuition is to use the built-in `mean` function, that's great, and there's a way to do it this way. However, because you are taking an average across `columns`, this will be a little complicated to code (the `mean` function generally operates across grouped `rows`). Accordingly, I recommend implementing this by simply hard-coding that the average of `a`, `b`, and `c` is `(a + b + c) / 3`.

```{r}

```

One of your colleagues makes a great point. Perhaps it makes sense to compute a weighted average by plate appearance. For example, Astros utilityman-turned-starting-centerfielder Mauricio Dubon had 187 plate appearances in 2021, 265 plate appearances in 2022, and 492 plate appearances in 2023. Weighting his batting average in each year equally likely doesn't make sense since he, among other ways to put this, got more plate appearances in 2023 than he did in 2021 and 2022 combined. This time, compute a weighted average. Again, there is a weighted average function and in general when aggregating across rows you should use it, but, since we are aggregating across columns here, I recommend hard-coding in a mutate.

*Remark*: look closely and you will see that Dubon played for two teams in 2022. Thinking back to last tutorial, remember how we could consolidate the two records (one for each team) that players like Dubon will have for 2022 into a single record. Make sure that this is part of your answer to this question. What happens to Mauricio Dubon rows in the dataframe if you don't do this consolidation when you perform joins, and why?

```{r}
# YOUR SOLUTION HERE
```

Which 25 hitters do you project to have the highest batting average using this approach?
```{r}
# YOUR SOLUTION HERE
```

Challenge (Optional): this is subtle and is a baseball question relating to specific stat definitions (not a coding question). Why is it a little bit weird to talk about plate appearances when performing a statistical analysis of batting average?

```{}
YOUR SOLUTION HERE
```

Challenge (Optional): instead of typing filter three times, redo the first part of this question using a for loop and the `rbind` function (Google this online). Moreover, research the `cbind` function (`cbind` will not be useful in the solution to this challenge question but is similar to `rbind` and worth learning at the same time if you choose to explore this).

```{r}
# YOUR SOLUTION HERE
```

Challenge (Optional and Complex): instead of using an average or a weighted average like we did above to form a batting average projection, use a linear regression model. Research linear regression as a concept first if you are not familiar with it. Then research the `lm()` function in R and write an appropriate function call. Describe your results. This challenge question, unless you are already familiar with linear regression, will likely take quite a bit longer than the other challenge questions in this tutorial (only do if it really interests you).
```{r}
# YOUR SOLUTION HERE
```
```{}
# YOUR COMMENTARY HERE
```

### Reflection: Underlying Statistical Biases?
This is tricky but give it a shot. A statistician may very well argue there's a significant issue with our analysis in the prior big example. Specifically, the statistician might take issue with rules, both explicitly by design and implicitly as a result of the functions we call, that might bias our dataset to not be a sample representative of the general population of MLB players. What might be some key points of the statistican's argument? Do you think the statistician is correct? (*Hint*: I think the statistician is right :-D)
```{}
YOUR REFLECTION HERE
```

# Visualization

At this point, you have been introduced to the foundations of how to condition data and join dataframes together. It is time to start making some visualizations. The go-to library for visualizations in R is `ggplot`, which for some reason goes by "ggplot2" when you import it. We have already loaded this library at the start of this module (and won't need to do it again), but you would import it just like any other library: `library(ggplot2)`.

Let's make a few example visuals based on the data you created earlier. This is the fun part: we get to make pretty pictures!

You have (hopefully) cleaned your data above like this, but, to make sure you can solve this part of the tutorial even if earlier answers are incorrect, use the following code to consolidate multi-record seasons for a given player.

```{r}
consolidate_multi_record_seasons = function(df) {
  df = df %>%
    group_by(Name) %>%
    mutate(across(where(is.double), ~mean(., na.rm = TRUE))) %>%
    mutate(across(where(is.integer), ~sum(., na.rm = TRUE))) %>%
    distinct(Name, .keep_all = TRUE)
  return(df)
}
bl_23 = consolidate_multi_record_seasons(bl_23)
bl_22 = consolidate_multi_record_seasons(bl_22)
bl_21 = consolidate_multi_record_seasons(bl_21)
```

Then join all of the data together:
```{r, message = FALSE, warning = FALSE}
joined_21_22_23 = bl_23 %>%
  inner_join(bl_22, by = c('Name' = 'Name'), suffix = c("_23", "_22")) %>%
  inner_join(bl_21, by = c('Name' = 'Name'), suffix = c("", "_21"))
```

## Scatterplot
Suppose I want to make a scatterplot of 2022 batting average and 2023 batting average.
```{r, message = FALSE, warning = FALSE}
ggplot(joined_21_22_23, aes(x = BA_22, y = BA_23)) +
  geom_point()
```
* Note that we started with the command `ggplot()` and pass the dataframe containing the data we want to plot as the first argument.

* Next, we pass `aes([content])`. `aes` refers to *aesthetics* and is where we specify the x-axis data and the y-axis data using `aes(x = [column], y = [column])`.

* `ggplot` always has the initial ggplot command (with the specified aesthetics inside) followed by a `+` and then a geometric specification. Here, we are telling it to plot points on the graph.

We can also make this visual fancier:

* It would be neat to add colors indicating the number of homeruns hit by the batter. Do players who hit more homeruns tend to have lower batting averages? We add color-coding by homeruns hit in the updated command below.

```{r, warning = FALSE, echo = FALSE}
ggplot(joined_21_22_23, aes(x = BA_22, y = BA_23, color = HR_22 + HR_23)) +
  geom_point() +
  scale_color_gradient(low = "blue", high = "red") +  # Define the color scale
  theme_minimal()  # Choose a theme
```

* This is slightly subtle, but, if two points exactly overlap, you only see it once on the scatterplot since there is no change in intensity regardless of whether a given point is a single point or a million points stacked on top of one another. This can make the visual a little bit deceptive since you cannot necessarily see where points that sit more or less exactly on top of each other are clustered.

```{r, warning = FALSE, echo = FALSE}
ggplot(joined_21_22_23, aes(x = BA_22, y = BA_23, color = HR_22 + HR_23)) +
  geom_point(alpha = 0.5) + # change the intensity of each point
  scale_color_gradient(low = "blue", high = "red") +
  theme_minimal()  
```
* Suppose we wanted R to fit a curve (with uncertainty bounds shown) to the relationship we observed between 2022 batting average and 2023 batting average. We can do this using ggplot as well. Note that there is someone with a 2023 batting average of 1 and someone with a 2022 batting average over 0.6. These are extreme outliers, which would yield a poor smoothing fit. I will remove them using a filter that requires at least 150 at bats in all years.
```{r, warning = FALSE, echo = FALSE}
joined_21_22_23 = joined_21_22_23 %>%
  filter(AB > 150, AB_22 > 150, AB_23 > 150)
ggplot(joined_21_22_23, aes(x = BA_22, y = BA_23, color = HR_22 + HR_23)) +
  geom_point(alpha = 0.5) +
  geom_smooth() + # add smoothed line
  scale_color_gradient(low = "blue", high = "red") +
  theme_minimal()
```

* I'm now adding a 45 degree line, which expresses what you would see if every player's batting average performance didn't change year-to-year. You can see how the smoothed fit is different from the hypothetical line to see how strong the relationship is. Note that I have also rescaled the axes

```{r, warning = FALSE, echo = FALSE}
joined_21_22_23 = joined_21_22_23 %>%
  filter(AB > 150, AB_22 > 150, AB_23 > 150)
ggplot(joined_21_22_23, aes(x = BA_22, y = BA_23, color = HR_22 + HR_23)) +
  xlim(0, 0.45) + # set x axis scale
  ylim(0, 0.45) + # set y axis scale
  geom_point(alpha = 0.5) +
  geom_smooth() +
  geom_abline(intercept = 0, slope = 1, color = "green") + # 45 degree line
  scale_color_gradient(low = "blue", high = "red") + 
  theme_minimal()
```
## Histogram

## Bar Plot

## Box Plot

## Hexagonal Plot

## Exercise: Make Your Own Visuals!

Create three visualizations using ggplot2 of your choosing. There's plenty of data in this document to use, but feel free to go out and acquire more data from *Baseball Reference* to solve fresh problems of interest to you. Try to design each visual so it tells a story. When you are done, present it to a classmate.
```{r}
# CODE FOR YOUR 3 VISUALS HERE
```

Create one really good visualization that relates to Luis Tiant. Note that you will need to go out and acquire data from Tiant's playing years. *Baseball Reference* is likely a great place to start.
```{r}
# CODE FOR LUIS TIANT VISUAL
```

## `ggplot` Reference Sheet

There's a phenomenal online reference sheet that helps tremendously with making `ggplot` visuals. Check it out [here](https://www.maths.usyd.edu.au/u/UG/SM/STAT3022/r/current/Misc/data-visualization-2.1.pdf). It's available a lot of places online. I don't remember most of the syntax for many visuals off the top of my head but consistently can recall it quickly using this cheat sheet!

# Conclusion

Congratulations on your hard work and for mastering even more areas of R. By now, you have a solid foundation in the basics and, with consistent practice, can take on your own data science projects. Personally, I love using sports as a way to learn data science. I once built a simulation framework to project playoff and championship probabilities for fantasy football teams and generate my own analytical projections every year. I used sports data as a way to practice building many types of models. Eventually, after a bunch of individual projects, I started doing work for teams. Being able to tell them about projects I had done and what I had learned from doing them helped a lot. The point is that if this is something you really enjoy (and it's okay to not know whether it is yet) it can be a great way to learn a lot of powerful computer science in an enjoyable way. You now have exposure to the foundational basics necessary to get started, and I'm always happy to chat if you have ideas or questions. Keep up the great work!


